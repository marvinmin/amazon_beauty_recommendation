{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the functions\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "from preprocessing_eda import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"../data/clean/TrainData.pkl\"):\n",
    "    df_train.sort_values(by = \"Timestamp\", inplace = True)\n",
    "    df_train.reset_index(drop = True, inplace = True)\n",
    "    df_train.to_pickle(\"../data/clean/TrainData.pkl\")\n",
    "else:\n",
    "    df_train = pd.read_pickle(\"../data/clean/TrainData.pkl\")\n",
    "\n",
    "if not os.path.isfile(\"../data/clean/TestData.pkl\"):\n",
    "    df_test.sort_values(by = \"Timestamp\", inplace = True)\n",
    "    df_test.reset_index(drop = True, inplace = True)\n",
    "    df_test.to_pickle(\"../data/clean/TestData.pkl\")\n",
    "else:\n",
    "    df_test = pd.read_pickle(\"../data/clean/TestData.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A27ZIX4Y4A8M65</td>\n",
       "      <td>B000005J9Q</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1998-10-18 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AXUC3MVPBT57K</td>\n",
       "      <td>B000005Z5L</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1998-11-28 16:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A18XELRYWMR80B</td>\n",
       "      <td>B00000IAI4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-03-15 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A22S1QH6GDUE1V</td>\n",
       "      <td>B000026BTH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1999-06-02 17:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUAZWQ8DULN43</td>\n",
       "      <td>B0000014DT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1999-09-13 17:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UserId   ProductId  Rating           Timestamp\n",
       "0  A27ZIX4Y4A8M65  B000005J9Q     4.0 1998-10-18 17:00:00\n",
       "1   AXUC3MVPBT57K  B000005Z5L     5.0 1998-11-28 16:00:00\n",
       "2  A18XELRYWMR80B  B00000IAI4     5.0 1999-03-15 17:00:00\n",
       "3  A22S1QH6GDUE1V  B000026BTH     5.0 1999-06-02 17:00:00\n",
       "4   AUAZWQ8DULN43  B0000014DT     4.0 1999-09-13 17:00:00"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the most similar item close to the highest rating the user gives to recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_user(data, user_id, N=5, user_key='UserId', item_key='ProductId'):\n",
    "    \"\"\"\n",
    "    Use the cosine similarity between items to make recommendations for a given user\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data: pandas.DataFrame\n",
    "        The original dataframe that stores the users' ratings information\n",
    "    user_id: str\n",
    "        The ID of the user to make recommendations\n",
    "    N: int (default=5)\n",
    "        The number of recommendations\n",
    "    ser_key: string\n",
    "        The column in ratings that contains the users id\n",
    "    item_key: string\n",
    "        The column in ratings that contains the items id\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    list of strings\n",
    "        The list of IDs of the recommended items.\n",
    "    \"\"\" \n",
    "    num_users = len(set(data[user_key]))\n",
    "    num_products = len(set(data[item_key]))\n",
    "    X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind = create_X(data, n=num_products, d=num_users, user_key=user_key, item_key=item_key)\n",
    "    Y = X.T\n",
    "    # Set dense_output to False to ge the sparse represent\n",
    "    similarity_matrix = cosine_similarity(X, dense_output=False)\n",
    "    \n",
    "    user_ind = user_mapper[user_id]\n",
    "    arr1, arr2 = Y[user_ind].nonzero()\n",
    "    \n",
    "    ratings = []\n",
    "    for i,j in zip(arr1, arr2):\n",
    "        ratings.append(Y[user_ind][i, j])\n",
    "    max_rating = np.max(ratings)\n",
    "    max_rating_ind = np.argmax(ratings)\n",
    "    \n",
    "    similar_arr1, similar_arr2 = similarity_matrix[arr2[max_rating_ind]].nonzero()\n",
    "    \n",
    "    similar_dict = {}\n",
    "    for i, j  in zip(similar_arr1, similar_arr2):\n",
    "        similar_dict[j] = similarity_matrix[arr2[max_rating_ind]][i,j]\n",
    "    \n",
    "    recom_list = sorted(similar_dict, key=similar_dict.get, reverse=True)\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    for ind in recom_list[1:]:\n",
    "        if Y[user_ind][0, ind] == 0:\n",
    "            res.append(item_inverse_mapper[ind])\n",
    "        if len(res) >= N:\n",
    "            break\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = recommend_for_user(df_train, user_id='A3RV5ZUA8W67FK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B000U8J8SM\">B000U8J8SM</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B00C4A4YHY\">B00C4A4YHY</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B00097E1UO\">B00097E1UO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B0061YLQTI\">B0061YLQTI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B0051U562Q\">B0051U562Q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in result:\n",
    "    display(HTML('<a href=\"%s\">%s</a>' % ('https://www.amazon.com/dp/' + item, \n",
    "                                      item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B0016P4P4K\">B0016P4P4K</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in df_train[df_train['UserId']=='A3RV5ZUA8W67FK']['ProductId']:\n",
    "    display(HTML('<a href=\"%s\">%s</a>' % ('https://www.amazon.com/dp/' + item, \n",
    "                                      item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_users = len(set(df_train['UserId']))\n",
    "num_products = len(set(df_train['ProductId']))\n",
    "X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind = create_X(df_train, n=num_products, d=num_users, user_key='UserId', item_key='ProductId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0838591]]\n",
      "[[0.0838591]]\n",
      "[[0.0838591]]\n",
      "[[0.0838591]]\n",
      "[[0.0838591]]\n"
     ]
    }
   ],
   "source": [
    "for item in result:\n",
    "    print(cosine_similarity(X[item_mapper['B0016P4P4K']], X[item_mapper[item]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the weighted average rating to recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IB_CF(data, user_id, N=5, user_key='UserId', item_key='ProductId'):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    num_users = len(set(data[user_key]))\n",
    "    num_products = len(set(data[item_key]))\n",
    "    X, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind = create_X(data, n=num_products, d=num_users, user_key=user_key, item_key=item_key)\n",
    "    Y = sparse_matrix((data[\"Rating\"], (user_ind, item_ind)), shape=(num_users, num_products))\n",
    "    # Set dense_output to False to ge the sparse represent\n",
    "    similarity_matrix = cosine_similarity(X, dense_output=False)\n",
    "    \n",
    "    user = user_mapper[user_id]\n",
    "    ratings = np.dot(Y[user], similarity_matrix)\n",
    "    _, arr = ratings.nonzero()\n",
    "    res = {}\n",
    "    for ind in arr:\n",
    "        if Y[user][0,ind] == 0:\n",
    "            res[ind] = ratings[0, ind]\n",
    "            \n",
    "    result = sorted(res, key=res.get, reverse=True)[:N]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = IB_CF(df_train, user_id='A3RV5ZUA8W67FK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B004XMUVSC\">B004XMUVSC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B0051U562Q\">B0051U562Q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B0061YLQTI\">B0061YLQTI</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B00097E1UO\">B00097E1UO</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://www.amazon.com/dp/B00C4A4YHY\">B00C4A4YHY</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item_ind in result1:\n",
    "    display(HTML('<a href=\"%s\">%s</a>' % ('https://www.amazon.com/dp/' + item_inverse_mapper[item_ind], \n",
    "                                      item_inverse_mapper[item_ind])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[121081, 123545, 138436, 8723, 194851]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0838591]]\n",
      "[[0.0838591]]\n",
      "[[0.0838591]]\n",
      "[[0.0838591]]\n",
      "[[0.0838591]]\n"
     ]
    }
   ],
   "source": [
    "for item_ind in result1:\n",
    "    print(cosine_similarity(X[item_mapper['B0016P4P4K']], X[item_ind]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(X, dense_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, temp_arr = similarity_matrix[item_mapper['B0016P4P4K']].nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {}\n",
    "for ind in temp_arr:\n",
    "    my_dict[ind] = similarity_matrix[item_mapper['B0016P4P4K']][0, ind]\n",
    "sorted_ind = sorted(my_dict, key=my_dict.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31941, 194851, 8723, 138436, 123545]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ind[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31941\n",
      "194851\n",
      "8723\n",
      "138436\n",
      "123545\n"
     ]
    }
   ],
   "source": [
    "for i in result:\n",
    "    print(item_mapper[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other approaches\n",
    "\n",
    "#### Ratings give to the same item by top 5 similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the training set\n",
    "if os.path.isfile(\"../data/clean/train_sparse_UI.npz\"):\n",
    "    train_sparse_UI = sparse.load_npz(\"../data/clean/train_sparse_UI.npz\")\n",
    "    \n",
    "else:\n",
    "    num_users_train = len(set(df_train['UserId']))\n",
    "    num_products_train = len(set(df_train['ProductId']))\n",
    "    train_sparse_IU, user_mapper, item_mapper, user_inverse_mapper, item_inverse_mapper, user_ind, item_ind\\\n",
    "    = create_X(df_train, n=num_products_train, d=num_users_train, user_key='UserId', item_key='ProductId')  \n",
    "    train_sparse_UI = train_sparse_IU.T\n",
    "    sparse.save_npz(\"../data/clean/train_sparse_UI.npz\", train_sparse_UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_sparse_matrix(sparseMatrix, n_users, n_items):\n",
    "    start = datetime.now()\n",
    "    users, items, ratings = sparse.find(sparseMatrix)\n",
    "    uniq_users = np.unique(users)\n",
    "    uniq_items = np.unique(items)\n",
    "    np.random.seed(15)   #this will give same random number everytime, without replacement\n",
    "    userS = np.random.choice(uniq_users, n_users, replace = False)\n",
    "    itemS = np.random.choice(uniq_items, n_items, replace = False)\n",
    "    mask = np.logical_and(np.isin(users, userS), np.isin(items, itemS))\n",
    "    sparse_sample = sparse.csr_matrix((ratings[mask], (users[mask], items[mask])), \n",
    "                                                     shape = (max(userS)+1, max(itemS)+1))\n",
    "    print(\"Sparse Matrix creation done. Saving it for later use.\")\n",
    "    sparse.save_npz(path, sparse_sample)\n",
    "    print(\"Done\")\n",
    "    print(\"Shape of Sparse Sampled Matrix = \"+str(sparse_sample.shape))\n",
    "    \n",
    "    print(datetime.now() - start)\n",
    "    return sparse_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is already present in the disk. Loading the file...\n",
      "File loading done.\n",
      "Shape of Train Sample Sparse Matrix = (1025570, 226768)\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/clean/TrainUISparseData_Sample.npz\"\n",
    "if not os.path.isfile(path):\n",
    "    print(\"Sample sparse matrix is not present in the disk. We are creating it...\")\n",
    "    train_sample_sparse = get_sample_sparse_matrix(train_sparse_UI, 100000, 10000)\n",
    "else:\n",
    "    print(\"File is already present in the disk. Loading the file...\")\n",
    "    train_sample_sparse = sparse.load_npz(path)\n",
    "    print(\"File loading done.\")\n",
    "    print(\"Shape of Train Sample Sparse Matrix = \"+str(train_sample_sparse.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train_users, sample_train_items, sample_train_ratings = sparse.find(train_sample_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7463"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAverageRatings(sparseMatrix, if_user):\n",
    "    ax = 1 if if_user else 0\n",
    "    #axis = 1 means rows and axis = 0 means columns \n",
    "    sumOfRatings = sparseMatrix.sum(axis = ax).A1 \n",
    "    noOfRatings = (sparseMatrix!=0).sum(axis = ax).A1  \n",
    "    rows, cols = sparseMatrix.shape\n",
    "    averageRatings = {i: sumOfRatings[i]/noOfRatings[i] for i in range(rows if if_user else cols) if noOfRatings[i]!=0}\n",
    "    return averageRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_user_rating = getAverageRatings(train_sparse_UI, True)\n",
    "average_item_rating = getAverageRatings(train_sparse_UI, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is already present in your disk. You do not have to prepare it again.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(\"../data/clean/Train_Regression.csv\"):\n",
    "    print(\"File is already present in your disk. You do not have to prepare it again.\")\n",
    "else:\n",
    "    startTime = datetime.now()\n",
    "    print(\"Preparing Train csv file for {} rows\".format(len(sample_train_ratings)))\n",
    "    train_sample_sparse_T = train_sample_sparse.T\n",
    "    with open(\"../data/clean/Train_Regression.csv\", mode = \"w\") as data:\n",
    "        count = 0\n",
    "        for user, item, rating in zip(sample_train_users, sample_train_items, sample_train_ratings):\n",
    "            row = list()\n",
    "            row.append(user)  #appending user index\n",
    "            row.append(item) #appending item index\n",
    "            row.append(train_sample_sparse.sum()/train_sample_sparse.count_nonzero()) #appending global average rating\n",
    "\n",
    "#----------------------------------Ratings given to \"item\" by top 5 similar users with \"user\"--------------------#\n",
    "            similar_users = cosine_similarity(train_sample_sparse[user], train_sample_sparse).ravel()\n",
    "            similar_users_indices = np.argsort(-similar_users)\n",
    "            similar_users_indices = similar_users_indices[similar_users_indices != user]\n",
    "            similar_users_ratings = train_sample_sparse[similar_users_indices, item].toarray().ravel()\n",
    "            top_similar_user_ratings = list(similar_users_ratings[similar_users_ratings != 0][:5])\n",
    "            top_similar_user_ratings.extend([average_item_rating[item]]*(5-len(top_similar_user_ratings)))\n",
    "            #above line means that if top 5 ratings are not available then rest of the ratings will be filled by \"item\" average\n",
    "            #rating. Let say only 3 out of 5 ratings are available then rest 2 will be \"item\" average rating.\n",
    "            row.extend(top_similar_user_ratings)\n",
    "            \n",
    " #----------------------------------Ratings given by \"user\" to top 5 similar items with \"items\"------------------#\n",
    "            similar_items = cosine_similarity(train_sample_sparse_T[item], train_sample_sparse_T).ravel()\n",
    "            similar_items_indices = np.argsort(-similar_items)\n",
    "            similar_items_indices = similar_items_indices[similar_items_indices != item]\n",
    "            similar_items_ratings = train_sample_sparse[user, similar_items_indices].toarray().ravel()\n",
    "            top_similar_item_ratings = list(similar_items_ratings[similar_items_ratings != 0][:5])\n",
    "            top_similar_item_ratings.extend([average_user_rating[user]]*(5-len(top_similar_item_ratings)))\n",
    "            #above line means that if top 5 ratings are not available then rest of the ratings will be filled by \"user\" average\n",
    "            #rating. Let say only 3 out of 5 ratings are available then rest 2 will be \"user\" average rating.\n",
    "            row.extend(top_similar_item_ratings)\n",
    "            \n",
    " #----------------------------------Appending \"user\" average, \"item\" average & rating of \"user\"\"item\"-----------#\n",
    "            row.append(average_user_rating[user])\n",
    "            row.append(average_item_rating[item])\n",
    "            row.append(rating)\n",
    "            \n",
    "#-----------------------------------Converting rows and appending them as comma separated values to csv file------#\n",
    "            data.write(\",\".join(map(str, row)))\n",
    "            data.write(\"\\n\")\n",
    "    \n",
    "            count += 1\n",
    "            if count % 2000 == 0:\n",
    "                print(\"Done for {}. Time elapsed: {}\".format(count, (datetime.now() - startTime)))\n",
    "                \n",
    "    print(\"Total Time for {} rows = {}\".format(len(sample_train_ratings), (datetime.now() - startTime)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ind</th>\n",
       "      <th>Item_ind</th>\n",
       "      <th>Global_Average</th>\n",
       "      <th>SUR1</th>\n",
       "      <th>SUR2</th>\n",
       "      <th>SUR3</th>\n",
       "      <th>SUR4</th>\n",
       "      <th>SUR5</th>\n",
       "      <th>SIR1</th>\n",
       "      <th>SIR2</th>\n",
       "      <th>SIR3</th>\n",
       "      <th>SIR4</th>\n",
       "      <th>SIR5</th>\n",
       "      <th>User_Average</th>\n",
       "      <th>Item_Average</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500635</td>\n",
       "      <td>17</td>\n",
       "      <td>4.144044</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>993665</td>\n",
       "      <td>17</td>\n",
       "      <td>4.144044</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.428571</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83620</td>\n",
       "      <td>83</td>\n",
       "      <td>4.144044</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>648587</td>\n",
       "      <td>177</td>\n",
       "      <td>4.144044</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>715917</td>\n",
       "      <td>177</td>\n",
       "      <td>4.144044</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4.565217</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ind  Item_ind  Global_Average  SUR1      SUR2      SUR3      SUR4  \\\n",
       "0    500635        17        4.144044   1.0  3.428571  3.428571  3.428571   \n",
       "1    993665        17        4.144044   5.0  3.428571  3.428571  3.428571   \n",
       "2     83620        83        4.144044   3.8  3.800000  3.800000  3.800000   \n",
       "3    648587       177        4.144044   5.0  5.000000  4.565217  4.565217   \n",
       "4    715917       177        4.144044   2.0  5.000000  4.565217  4.565217   \n",
       "\n",
       "       SUR5      SIR1      SIR2      SIR3      SIR4      SIR5  User_Average  \\\n",
       "0  3.428571  5.000000  4.666667  4.666667  4.666667  4.666667      4.666667   \n",
       "1  3.428571  1.000000  1.000000  1.000000  1.000000  1.000000      1.000000   \n",
       "2  3.800000  4.000000  4.000000  4.000000  4.000000  4.000000      4.000000   \n",
       "3  4.565217  2.000000  2.000000  2.000000  2.000000  2.000000      2.000000   \n",
       "4  4.565217  4.666667  4.666667  4.666667  4.666667  4.666667      4.666667   \n",
       "\n",
       "   Item_Average  Rating  \n",
       "0      3.428571     5.0  \n",
       "1      3.428571     1.0  \n",
       "2      3.800000     3.0  \n",
       "3      4.565217     2.0  \n",
       "4      4.565217     5.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train_Reg = pd.read_csv(\"../data/clean/Train_Regression.csv\", names = [\"User_ind\", \"Item_ind\", \"Global_Average\", \"SUR1\", \"SUR2\", \"SUR3\", \"SUR4\", \"SUR5\", \"SIR1\", \"SIR2\", \"SIR3\", \"SIR4\", \"SIR5\", \"User_Average\", \"Item_Average\", \"Rating\"])\n",
    "Train_Reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan Values: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of nan Values: \"+str(Train_Reg.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train DataFrame: (7463, 16)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Train DataFrame: {}\".format(Train_Reg.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the test set\n",
    "if os.path.isfile(\"../data/clean/test_sparse_UI.npz\"):\n",
    "    test_sparse_UI = sparse.load_npz(\"../data/clean/test_sparse_UI.npz\")\n",
    "    \n",
    "else:\n",
    "    num_users_test = len(set(df_test['UserId']))\n",
    "    num_products_test = len(set(df_test['ProductId']))\n",
    "    test_sparse_IU, user_mapper_test, item_mapper_test, user_inverse_mapper_test, item_inverse_mapper_test, user_ind_test, item_ind_test\\\n",
    "    = create_X(df_test, n=num_products_test, d=num_users_test, user_key='UserId', item_key='ProductId')  \n",
    "    test_sparse_UI = test_sparse_IU.T\n",
    "    sparse.save_npz(\"../data/clean/test_sparse_UI.npz\", test_sparse_UI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is already present in the disk. Loading the file...\n",
      "File loading done.\n",
      "Shape of Test Sample Sparse Matrix = (331226, 113835)\n"
     ]
    }
   ],
   "source": [
    "path = \"../data/clean/TestUISparseData_Sample.npz\"\n",
    "if not os.path.isfile(path):\n",
    "    print(\"Sample sparse matrix is not present in the disk. We are creating it...\")\n",
    "    test_sample_sparse = get_sample_sparse_matrix(test_sparse_UI, 50000, 5000)\n",
    "else:\n",
    "    print(\"File is already present in the disk. Loading the file...\")\n",
    "    test_sample_sparse = sparse.load_npz(path)\n",
    "    print(\"File loading done.\")\n",
    "    print(\"Shape of Test Sample Sparse Matrix = \"+str(test_sample_sparse.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_users, sample_test_items, sample_test_ratings = sparse.find(test_sample_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2677"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_test_ratings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
